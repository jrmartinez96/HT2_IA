{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import utils.mnist_reader as mnist_reader\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "El primer paso es crear una funcion para crear una red neuronal que reciba como parametros la cantidad de neuronas de input, la cantidad de layer, la cantidad de neuronas en las hidden layers y la cantidad de neuronas de output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}, {'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}]\n",
      "[{'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}, {'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014]}, {'weights': [0.7215400323407826, 0.22876222127045265, 0.9452706955539223]}]\n",
      "[{'weights': [0.9014274576114836, 0.030589983033553536, 0.0254458609934608, 0.5414124727934966]}, {'weights': [0.9391491627785106, 0.38120423768821243, 0.21659939713061338, 0.4221165755827173]}]\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs, l_hidden):\n",
    "    network = list() \n",
    "    for layer in range(l_hidden): \n",
    "        hidden_layer = [{'weights':[rd.random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "        network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[rd.random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "# Prueba de crear una red\n",
    "rd.seed(1)\n",
    "network = initialize_network(2, 3, 2, 2)\n",
    "for layer in network:\n",
    "    print(layer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "El siguiente paso es crear una funcion que haga un forward propagate que reciba como parametros la red neuronal y una lista de inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7766186921595404, 0.8276836706697595]\n"
     ]
    }
   ],
   "source": [
    "# Calcula la activacion de la neurona considerando todos los pesos e inputs que tiene\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    " \n",
    "# Transforma la cativacion al output que tendr치 la neurona\n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + math.exp(-activation))\n",
    " \n",
    "# Realiza el forward propagate de la red neuronal\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs\n",
    "\n",
    "# Prueba de forward propagate\n",
    "rd.seed(1)\n",
    "network = initialize_network(2, 3, 2, 2)\n",
    "row = [1,0]\n",
    "output = forward_propagate(network, row)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lo siguiente es una implementacion del error del backward propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 0.7105668883115941, 'delta': 8.949373877119777e-05}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381], 'output': 0.6691980263750579, 'delta': -0.0035442273587705615}, {'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349], 'output': 0.678187028346445, 'delta': -0.0016613352092108096}]\n",
      "[{'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337], 'output': 0.733450902916955, 'delta': -0.01923100377076876}, {'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014], 'output': 0.7287811747842476, 'delta': 0.001037164080907111}, {'weights': [0.7215400323407826, 0.22876222127045265, 0.9452706955539223], 'output': 0.8335585539346707, 'delta': 0.0002628979455481982}]\n",
      "[{'weights': [0.9014274576114836, 0.030589983033553536, 0.0254458609934608, 0.5414124727934966], 'output': 0.7766186921595404, 'delta': -0.13472944095336908}, {'weights': [0.9391491627785106, 0.38120423768821243, 0.21659939713061338, 0.4221165755827173], 'output': 0.8276836706697595, 'delta': 0.024576342828326648}]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "# Prueba de back propagate\n",
    "rd.seed(1)\n",
    "network = initialize_network(2, 3, 2, 2)\n",
    "row = [1,0]\n",
    "forward_propagate(network, row)\n",
    "expected = [0, 1]\n",
    "backward_propagate_error(network, expected)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora que ya se puede realizar el back propagate para una prueba se necesitan actualizar los pesos de cada neurona.\n",
    "Aqui se define el learning rate el cual controla el cambio del peso para corregir el error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] += l_rate * neuron['delta']\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ya teniendo la funcion de actualizar el peso se puede proceder a tener una funcion para entrenar la red neuronal.\n",
    "El numero de epoch es la cantidad de veces que se entrena치 la red con los mismos datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1].astype(np.int64)] = 1\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ya teniendo la funcion para calcular el error del backpropagate y para entrenar la red neuronal ahora tenemos que predecir.\n",
    "Esto se lograr치 teniendo una funcion que prediga teniendo la red neuronal y una fila de inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(network, row):\n",
    "\toutputs = forward_propagate(network, row)\n",
    "\treturn outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Esto es todo lo que se necesita para poder formar una funcion que utilice el algoritmo de backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden, l_hidden):\n",
    "\tn_inputs = len(train[0]) - 1\n",
    "\tn_outputs = len(set([row[-1] for row in train]))\n",
    "\tnetwork = initialize_network(n_inputs, n_hidden, 10, l_hidden)\n",
    "\ttrain_network(network, train, l_rate, n_epoch, 10)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\tprediction = predict(network, row)\n",
    "\t\tpredictions.append(prediction)\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora que ya se tiene el algoritmo de backward propagation es importante mencionar que para hacer que las pruebas sean bien implementadas se utilizar치 cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = rd.randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora lo unico que nos queda por hacer es normalizar los datos para que puedan tener un valor entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset):\n",
    "    minmax = list()\n",
    "    stats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "    for row in dataset:\n",
    "\t    for i in range(len(row)-1):\n",
    "\t\t    row[i] = (row[i] - stats[i][0]) / (stats[i][1] - stats[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora que ya tenemos el algoritmo de backward propagation y el dataset dividido en n_folds utilizando cross validation tenemos que\n",
    "integrar cross validation con backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        #train_set = list(folds)\n",
    "        #train_set.remove(fold)\n",
    "        train_set = list()\n",
    "        for foldd in folds:\n",
    "            if np.array_equal(foldd, fold):\n",
    "                train_set.append(foldd)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Conversiones de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# funcion para convertir a float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = row[column].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora que ya se tienen todas las piezas del rompecabezas unidas ya se puede probar la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Se une los el resultado esperado al dataset en la ultima columna\n",
    "y_trans = np.array([y_train]).T\n",
    "dataset = np.append(X_train.copy().astype(float), y_trans, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rd.seed(1)\n",
    "normalize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset2 = dataset.copy()[:10000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Scores: [10.0, 8.0, 9.85, 9.6, 9.65]\n",
      "Mean Accuracy: 9.420%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "l_rate = 0.3\n",
    "n_epoch = 1\n",
    "n_hidden = 300\n",
    "l_hidden = 1\n",
    "scores = evaluate_algorithm(dataset2, back_propagation, n_folds, l_rate, n_epoch, n_hidden, l_hidden)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}